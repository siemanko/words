{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codenames_words = [\"africa\", \"agent\", \"air\", \"alien\", \"alps\", \"amazon\", \"ambulance\", \"america\", \"angel\", \"antarctica\", \"apple\", \"arm\", \"atlantis\", \"australia\", \"aztec\", \"back\", \"ball\", \"band\", \"bank\", \"bar\", \"bark\", \"bat\", \"battery\", \"beach\", \"bear\", \"beat\", \"bed\", \"beijing\", \"bell\", \"belt\", \"berlin\", \"bermuda\", \"berry\", \"bill\", \"block\", \"board\", \"bolt\", \"bomb\", \"bond\", \"boom\", \"boot\", \"bottle\", \"bow\", \"box\", \"bridge\", \"brush\", \"buck\", \"buffalo\", \"bug\", \"bugle\", \"button\", \"calf\", \"canada\", \"cap\", \"capital\", \"car\", \"card\", \"carrot\", \"casino\", \"cast\", \"cat\", \"cell\", \"centaur\", \"center\", \"chair\", \"change\", \"charge\", \"check\", \"chest\", \"chick\", \"china\", \"chocolate\", \"church\", \"circle\", \"cliff\", \"cloak\", \"club\", \"code\", \"cold\", \"comic\", \"compound\", \"concert\", \"conductor\", \"contract\", \"cook\", \"copper\", \"cotton\", \"court\", \"cover\", \"crane\", \"crash\", \"cricket\", \"cross\", \"crown\", \"cycle\", \"czech\", \"dance\", \"date\", \"day\", \"death\", \"deck\", \"degree\", \"diamond\", \"dice\", \"dinosaur\", \"disease\", \"doctor\", \"dog\", \"draft\", \"dragon\", \"dress\", \"drill\", \"drop\", \"duck\", \"dwarf\", \"eagle\", \"egypt\", \"embassy\", \"engine\", \"england\", \"europe\", \"eye\", \"face\", \"fair\", \"fall\", \"fan\", \"fence\", \"field\", \"fighter\", \"figure\", \"file\", \"film\", \"fire\", \"fish\", \"flute\", \"fly\", \"foot\", \"force\", \"forest\", \"fork\", \"france\", \"game\", \"gas\", \"genius\", \"germany\", \"ghost\", \"giant\", \"glass\", \"glove\", \"gold\", \"grace\", \"grass\", \"greece\", \"green\", \"ground\", \"ham\", \"hand\", \"hawk\", \"head\", \"heart\", \"helicopter\", \"himalayas\", \"hole\", \"hollywood\", \"honey\", \"hood\", \"hook\", \"horn\", \"horse\", \"horseshoe\", \"hospital\", \"hotel\", \"ice\", \"icecream\", \"india\", \"iron\", \"ivory\", \"jack\", \"jam\", \"jet\", \"jupiter\", \"kangaroo\", \"ketchup\", \"key\", \"kid\", \"king\", \"kiwi\", \"knife\", \"knight\", \"lab\", \"lap\", \"laser\", \"lawyer\", \"lead\", \"lemon\", \"leprechaun\", \"life\", \"light\", \"limousine\", \"line\", \"link\", \"lion\", \"litter\", \"loch ness\", \"lock\", \"log\", \"london\", \"luck\", \"mail\", \"mammoth\", \"maple\", \"marble\", \"march\", \"mass\", \"match\", \"mercury\", \"mexico\", \"microscope\", \"millionaire\", \"mine\", \"mint\", \"missile\", \"model\", \"mole\", \"moon\", \"moscow\", \"mount\", \"mouse\", \"mouth\", \"mug\", \"nail\", \"needle\", \"net\", \"new york\", \"night\", \"ninja\", \"note\", \"novel\", \"nurse\", \"nut\", \"octopus\", \"oil\", \"olive\", \"olympus\", \"opera\", \"orange\", \"organ\", \"palm\", \"pan\", \"pants\", \"paper\", \"parachute\", \"park\", \"part\", \"pass\", \"paste\", \"penguin\", \"phoenix\", \"piano\", \"pie\", \"pilot\", \"pin\", \"pipe\", \"pirate\", \"pistol\", \"pit\", \"pitch\", \"plane\", \"plastic\", \"plate\", \"platypus\", \"play\", \"plot\", \"point\", \"poison\", \"pole\", \"police\", \"pool\", \"port\", \"post\", \"pound\", \"press\", \"princess\", \"pumpkin\", \"pupil\", \"pyramid\", \"queen\", \"rabbit\", \"racket\", \"ray\", \"revolution\", \"ring\", \"robin\", \"robot\", \"rock\", \"rome\", \"root\", \"rose\", \"roulette\", \"round\", \"row\", \"ruler\", \"satellite\", \"saturn\", \"scale\", \"school\", \"scientist\", \"scorpion\", \"screen\", \"scuba diver\", \"seal\", \"server\", \"shadow\", \"shakespeare\", \"shark\", \"ship\", \"shoe\", \"shop\", \"shot\", \"sink\", \"skyscraper\", \"slip\", \"slug\", \"smuggler\", \"snow\", \"snowman\", \"sock\", \"soldier\", \"soul\", \"sound\", \"space\", \"spell\", \"spider\", \"spike\", \"spine\", \"spot\", \"spring\", \"spy\", \"square\", \"stadium\", \"staff\", \"star\", \"state\", \"stick\", \"stock\", \"straw\", \"stream\", \"strike\", \"string\", \"sub\", \"suit\", \"superhero\", \"swing\", \"switch\", \"table\", \"tablet\", \"tag\", \"tail\", \"tap\", \"teacher\", \"telescope\", \"temple\", \"theater\", \"thief\", \"thumb\", \"tick\", \"tie\", \"time\", \"tokyo\", \"tooth\", \"torch\", \"tower\", \"track\", \"train\", \"triangle\", \"trip\", \"trunk\", \"tube\", \"turkey\", \"undertaker\", \"unicorn\", \"vacuum\", \"van\", \"vet\", \"wake\", \"wall\", \"war\", \"washer\", \"washington\", \"watch\", \"water\", \"wave\", \"web\", \"well\", \"whale\", \"whip\", \"wind\", \"witch\", \"worm\", \"yard\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26660, (26660, 300), '31 MB')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "word = []\n",
    "vec = []\n",
    "\n",
    "max_words = 30000\n",
    "\n",
    "with open(\"/Users/szymon/Downloads/google-10000-english-usa.txt\") as f:\n",
    "    common_words = f.read().strip().split('\\n')\n",
    "    \n",
    "needed = set(common_words + codenames_words)\n",
    "with open(\"/Users/szymon/Downloads/glove.42B.300d.txt\") as f:\n",
    "    for word_idx, line in enumerate(itertools.islice(f, 100000)):\n",
    "        w, v = line.strip().split(' ', 1)\n",
    "        v = np.array(list(map(float, v.split(' '))), dtype=np.float32)\n",
    "        if not w.isalpha() or not w.isascii() or (word_idx >= max_words and w not in needed):\n",
    "            continue\n",
    "        word.append(w)\n",
    "        vec.append(v)\n",
    "        \n",
    "# hacks\n",
    "vec.append((vec[word.index('new')] + vec[word.index('york')]) / 2)\n",
    "word.append('new york')\n",
    "vec.append((vec[word.index('loch')] + vec[word.index('ness')]) / 2)\n",
    "word.append('loch ness')\n",
    "vec.append((vec[word.index('scuba')] + vec[word.index('diver')]) / 2)\n",
    "word.append('scuba diver')\n",
    "# end hacks\n",
    "\n",
    "vec = np.stack(vec)\n",
    "word_to_idx = {w: idx for idx, w in enumerate(word)}\n",
    "def word_to_vec(w):\n",
    "    return vec[word_to_idx[w]]\n",
    "\n",
    "vec /= np.linalg.norm(vec, axis=-1)[:, None]\n",
    "# vec = PCA(n_components=128).fit_transform(vec)\n",
    "len(word), vec.shape, f'{vec.size * vec.itemsize // 10**6} MB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft -> softer is like hard -> harder [tougher, easier, faster, better]\n",
      "airplane -> air is like boat -> water [sea, ocean, river, pump]\n",
      "woman -> man is like queen -> king [prince, kings, royal, crown]\n",
      "bedroom -> bed is like restroom -> toilet [toilets, shower, wheelchair, hygiene]\n",
      "big -> small is like long -> short [longer, relatively, large, few]\n",
      "god -> angel is like devil -> demon [witch, kitty, raven, ghost]\n",
      "computer -> keyboard is like car -> truck [pedal, vehicle, suv, guitar]\n",
      "employee -> boss is like soldier -> hero [boy, man, warrior, army]\n",
      "int -> float is like integer -> floating [decimal, arithmetic, numeric, binary]\n",
      "new york -> usa is like paris -> france [belgium, europe, switzerland, germany]\n",
      "loch ness -> uk is like salem -> usa [united, hampshire, massachusetts, london]\n",
      "scuba diver -> water is like astronaut -> nasa [space, earth, milk, moon]\n",
      "CPU times: user 198 ms, sys: 54.7 ms, total: 253 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ANALOGIES = [\n",
    "    ('soft', 'softer', 'hard'),\n",
    "    ('airplane', 'air', 'boat'),\n",
    "    ('woman', 'man', 'queen'),\n",
    "    ('bedroom', 'bed', 'restroom'),\n",
    "    ('big', 'small', 'long'),\n",
    "    ('god', 'angel', 'devil'),\n",
    "    ('computer', 'keyboard', 'car'),\n",
    "    ('employee', 'boss', 'soldier'),\n",
    "    ('int', 'float', 'integer'),\n",
    "    # unit tests for hacky words:\n",
    "    ('new york', 'usa', 'paris'),\n",
    "    ('loch ness', 'uk', 'salem'),\n",
    "    ('scuba diver', 'water', 'astronaut'),\n",
    "]\n",
    "\n",
    "def derived_from(word, sources):\n",
    "    for src in sources:\n",
    "        if word == src or word == src + 's':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for srcfrom, srcto, dstfrom in ANALOGIES:\n",
    "    targetvec = word_to_vec(srcto) - word_to_vec(srcfrom) + word_to_vec(dstfrom) \n",
    "    dist = (1 - (vec * targetvec[None, :])).sum(-1)\n",
    "    candidates = [word[idx] for idx in dist.argsort()[:100]]\n",
    "    candidates = [w for w in candidates if not derived_from(w, [srcfrom, srcto, dstfrom])][:5]\n",
    "\n",
    "    print(f'{srcfrom} -> {srcto} is like {dstfrom} -> {candidates[0]} [{\", \".join(candidates[1:])}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = set(word)\n",
    "for w in codenames_words:\n",
    "    if w not in glove_words:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47582853 0.5133306  0.54044765 0.5138103  0.5261601 ]\n",
      "[[0.51287854 0.58915204 0.69899464]\n",
      " [0.56543154 0.59968007 0.7987106 ]\n",
      " [0.5481349  0.60924804 0.7807704 ]]\n",
      "max score 0.06720805\n",
      "good: ['church', 'cat', 'atlantis']\n",
      "bad: ['eye', 'aztec', 'buck', 'pin', 'hospital']\n",
      "fail: ['fair']\n",
      "\n",
      "ark 0.06720805\n",
      "lazarus 0.0562582\n",
      "aston 0.05493933\n",
      "jacuzzi 0.05282885\n",
      "interlude 0.05101335\n",
      "skydiving 0.048659146\n",
      "sauna 0.048546195\n",
      "soundtracks 0.048202276\n",
      "reactor 0.048033893\n",
      "cayman 0.047184587\n",
      "\n",
      "---\n",
      "\n",
      "[0.42217493 0.5122403  0.44222897 0.48202395 0.48491848]\n",
      "[[0.5619298  0.66426396 0.7364072 ]\n",
      " [0.60418576 0.6906879  0.69164383]\n",
      " [0.62309116 0.6565501  0.7291641 ]]\n",
      "max score 0.11440015\n",
      "good: ['iron', 'ham', 'beijing']\n",
      "bad: ['witch', 'note', 'cat', 'bear', 'ambulance']\n",
      "fail: ['fall']\n",
      "\n",
      "wok 0.11440015\n",
      "tong 0.10378122\n",
      "nonstick 0.086284816\n",
      "moroccan 0.057478428\n",
      "ge 0.053643763\n",
      "btu 0.048133075\n",
      "gloucester 0.045795977\n",
      "porto 0.045105636\n",
      "isi 0.04210043\n",
      "dynamo 0.039309084\n",
      "\n",
      "---\n",
      "\n",
      "[0.5562968  0.57261956 0.5995827  0.5611601  0.5342404 ]\n",
      "[[0.5269017  0.61119956 0.6247083 ]\n",
      " [0.5217447  0.59829664 0.6307243 ]\n",
      " [0.5467294  0.6299541  0.6540204 ]]\n",
      "max score 0.13290346\n",
      "good: ['robin', 'screen', 'server']\n",
      "bad: ['pole', 'plate', 'ground', 'pupil', 'iron']\n",
      "fail: ['novel']\n",
      "\n",
      "saved 0.13290346\n",
      "flickr 0.13283372\n",
      "email 0.13182133\n",
      "dir 0.13131678\n",
      "emailed 0.12921989\n",
      "chat 0.11624861\n",
      "chats 0.11239332\n",
      "uploaded 0.11096424\n",
      "icq 0.1091522\n",
      "yahoo 0.10472\n",
      "\n",
      "---\n",
      "\n",
      "CPU times: user 264 ms, sys: 52.6 ms, total: 317 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_distances(targetvec):\n",
    "    return (1 - (vec * targetvec[None, :]).sum(-1))\n",
    "EXAMPLES = [\n",
    "    {\n",
    "        'good': [\"church\", \"cat\", \"atlantis\"],\n",
    "        'bad': [\"eye\", \"aztec\", \"buck\", \"pin\", \"hospital\"],\n",
    "        'fail': [\"fair\"],\n",
    "    },\n",
    "    {\n",
    "        'good': [\"iron\", \"ham\", \"beijing\"],\n",
    "        'bad': [\"witch\", \"note\", \"cat\", \"bear\", \"ambulance\"],\n",
    "        'fail': [\"fall\"],\n",
    "    },\n",
    "    {\n",
    "        'good': [\"robin\", \"screen\", \"server\"],\n",
    "        'bad': [\"pole\", \"plate\", \"ground\", \"pupil\", \"iron\"],\n",
    "        'fail': [\"novel\"],\n",
    "    }\n",
    "]\n",
    "\n",
    "for ex in EXAMPLES:\n",
    "    good_distances = np.concatenate([get_distances(word_to_vec(w))[:, None] for w in ex['good']], -1)\n",
    "    bad_distances = np.concatenate([get_distances(word_to_vec(w))[:, None] for w in ex['bad']], -1)\n",
    "    fail_distances = np.concatenate([get_distances(word_to_vec(w))[:, None] for w in ex['fail']], -1)\n",
    "    \n",
    "    risk = 1\n",
    "    num_guessed = 3\n",
    "    bad_score = np.minimum(fail_distances[:, 0], np.sort(bad_distances, -1)[:, risk])\n",
    "    print(bad_score[:5])\n",
    "    good_score = -np.sort(good_distances, -1)[:, :num_guessed].max(-1)\n",
    "#     print(good_score[:5])\n",
    "    print(np.sort(good_distances, -1)[:3])\n",
    "\n",
    "    score = bad_score + good_score\n",
    "    candidates = [word[idx] for idx in (-score).argsort()[:1000]][:10]\n",
    "    print('max score', score.max())\n",
    "    print('good:', ex['good'])\n",
    "    print('bad:', ex['bad'])\n",
    "    print('fail:', ex['fail'])\n",
    "    print()\n",
    "    for c in candidates:\n",
    "        print(c, score[word_to_idx[c]])\n",
    "    print()\n",
    "    print('---')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/szymon/Downloads/google-10000-english-no-swears.txt\") as f:\n",
    "    common_words_no_swears = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26660"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7998000\n"
     ]
    }
   ],
   "source": [
    "b = vec.flatten()#np.array(list(range(1000)), dtype=np.float32).tobytes()\n",
    "print(len(b))\n",
    "with open(\"vec.bytes\", 'wb') as f:\n",
    "    f.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_word_forms = {w: get_forms(w, threshold=0.5) for w in word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"word.json\", 'wt') as f:\n",
    "    json.dump({\n",
    "        'word': word,\n",
    "        'common_words': common_words_no_swears,\n",
    "        'other_word_forms': other_word_forms,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "tagger = UnigramTagger(brown.tagged_sents(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "ALL_POS_TAGS = [wordnet.ADJ, wordnet.VERB, wordnet.NOUN, wordnet.ADV, wordnet.ADJ_SAT]\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(word, from_pos, to_pos):    \n",
    "    synsets = wn.synsets(word, pos=from_pos)\n",
    "\n",
    "    # Word not found\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Get all lemmas of the word (consider 'a'and 's' equivalent)\n",
    "    lemmas = []\n",
    "    for s in synsets:\n",
    "        for l in s.lemmas():\n",
    "            if s.name().split('.')[1] == from_pos or from_pos in (wordnet.ADJ, wordnet.ADJ_SAT) and s.name().split('.')[1] in (wordnet.ADJ, wordnet.ADJ_SAT):\n",
    "                lemmas += [l]\n",
    "\n",
    "    # Get related forms\n",
    "    derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "\n",
    "    # filter only the desired pos (consider 'a' and 's' equivalent)\n",
    "    related_noun_lemmas = []\n",
    "\n",
    "    for drf in derivationally_related_forms:\n",
    "        for l in drf[1]:\n",
    "            if l.synset().name().split('.')[1] == to_pos or to_pos in (wordnet.ADJ, wordnet.ADJ_SAT) and l.synset().name().split('.')[1] in (wordnet.ADJ, wordnet.ADJ_SAT):\n",
    "                related_noun_lemmas += [l]\n",
    "\n",
    "    # Extract the words from the lemmas\n",
    "    words = [l.name() for l in related_noun_lemmas]\n",
    "    len_words = len(words)\n",
    "\n",
    "    # Build the result in the form of a list containing tuples (word, probability)\n",
    "    result = [(w, float(words.count(w)) / len_words) for w in set(words)]\n",
    "    result.sort(key=lambda w:-w[1])\n",
    "\n",
    "    # return all the possibilities sorted by probability\n",
    "    return result\n",
    "\n",
    "def convert_single(*args, **kwargs):\n",
    "    t = kwargs.pop('threshold', 0.5)\n",
    "    res = convert(*args, **kwargs)\n",
    "    if len(res) > 0 and res[0][1] >= t:\n",
    "        return res[0][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_single('flight', 'n', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('competitive', 'directness', 'medical')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_single('fight', 'n', 'a'), convert_single('direct', 'a', 'n'), convert_single('medicine', 'n', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "website ['websit']\n",
      "fought ['fight', 'oppon', 'opponent']\n",
      "better ['good', 'honor']\n",
      "bongs ['bong']\n",
      "flies ['fli', 'fly']\n",
      "medication ['medic']\n",
      "medic []\n",
      "flight ['fli', 'fly']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_forms(word, threshold=0.5):\n",
    "    tag = tagger.tag([word])[0][1]\n",
    "    if tag is not None:\n",
    "        tag = get_wordnet_pos(tag)\n",
    "    if tag is not None:\n",
    "        res = lemmatizer.lemmatize(word, pos=tag)\n",
    "    else:\n",
    "        res = lemmatizer.lemmatize(word)\n",
    "    forms = [word, res]\n",
    "    \n",
    "    if tag is not None:\n",
    "        for other_tag in ALL_POS_TAGS:\n",
    "            if other_tag == tag:\n",
    "                continue\n",
    "            other_pos_res = convert_single(res, tag, other_tag, threshold=threshold)\n",
    "            if other_pos_res is not None:\n",
    "                forms.append(other_pos_res)\n",
    "    forms.extend([ps.stem(f) for f in forms])\n",
    "    return sorted(set(forms).difference([word]))\n",
    "\n",
    "for word in ['website', 'fought', 'better', 'bongs', 'flies', 'medication', 'medic', 'flight']:\n",
    "    print(word, get_forms(word, threshold=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in common_words_no_swears[1000:1100]:\n",
    "    print(w)\n",
    "    print('  ', get_forms(w, threshold=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['webpag']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_word_forms['webpage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['websit']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_word_forms['website']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = ['access', 'action', 'addition', 'adventure', 'advisor', 'airline', 'airport', 'alien', 'american', 'angel', 'ankle', 'apollo', 'archer', 'arena', 'ares', 'arm', 'arrow', 'assassin', 'astronaut', 'author', 'automaton', 'bacon', 'bag', 'ball', 'ballet', 'band', 'banner', 'bar', 'barrel', 'bartender', 'beam', 'bear', 'bell', 'belt', 'bench', 'bet', 'bigfoot', 'bird', 'bite', 'black', 'blade', 'blog', 'boat', 'bolt', 'bomb', 'bone', 'bow', 'bowling', 'box', 'boy', 'break', 'breath', 'bronze', 'brownie', 'browser', 'brush', 'bull', 'bullet', 'butter', 'cable', 'cafe', 'cage', 'cake', 'camera', 'canon', 'cap', 'capitol', 'care', 'carrier', 'cereal', 'ceremony', 'chain', 'character', 'cheek', 'chicken', 'cinema', 'circus', 'city', 'class', 'clone', 'club', 'cod', 'coffee', 'comic', 'connection', 'corn', 'corner', 'corpse', 'cosmos', 'cotton', 'course', 'cow', 'crab', 'cracker', 'crew', 'cross', 'crown', 'crystal', 'cupcake', 'current', 'customer', 'czech', 'dagger', 'death', 'demon', 'devil', 'dinner', 'director', 'directory', 'dolphin', 'dragon', 'drain', 'drive', 'drop', 'eagle', 'egypt', 'elephant', 'elf', 'episode', 'equator', 'face', 'faith', 'fan', 'fantasy', 'farm', 'feather', 'fiction', 'field', 'fight', 'file', 'fire', 'fist', 'floor', 'fly', 'forearm', 'forehead', 'forest', 'fox', 'freezer', 'french', 'frog', 'funeral', 'fur', 'future', 'game', 'garden', 'gate', 'ghost', 'ginger', 'glass', 'glove', 'goat', 'gold', 'golf', 'government', 'gown', 'grill', 'guitar', 'hall', 'hammer', 'hamster', 'hand', 'handle', 'hell', 'hill', 'hole', 'hood', 'hook', 'hose', 'hospital', 'house', 'hunt', 'hymn', 'ice', 'inch', 'inverse', 'italy', 'japan', 'jar', 'jaw', 'jellyfish', 'jersey', 'jerusalem', 'jug', 'jump', 'kennel', 'key', 'kiss', 'kite', 'kitten', 'knight', 'kolkata', 'lake', 'lamp', 'latvia', 'left', 'lid', 'lincoln', 'lion', 'lip', 'lithuania', 'lock', 'lodge', 'london', 'luck', 'magic', 'mango', 'manhattan', 'market', 'martian', 'mathematics', 'maze', 'mermaid', 'mesh', 'meter', 'mind', 'mirror', 'monopoly', 'month', 'moon', 'moose', 'motorcycle', 'mountain', 'movie', 'musical', 'nepal', 'network', 'news', 'night', 'nose', 'note', 'ocean', 'octopus', 'officer', 'opening', 'order', 'oval', 'oven', 'owl', 'pack', 'panda', 'paris', 'park', 'paw', 'paws', 'peach', 'peanut', 'pearl', 'pen', 'pepper', 'performer', 'pharmacist', 'physician', 'pink', 'pirate', 'pit', 'pittsburgh', 'pizza', 'plane', 'plant', 'play', 'pocket', 'poem', 'poker', 'police', 'poodle', 'prayer', 'present', 'priest', 'prince', 'prometheus', 'puppy', 'purple', 'puzzle', 'raccoon', 'radar', 'radio', 'rainbow', 'raptor', 'rat', 'reef', 'reference', 'reindeer', 'report', 'rice', 'river', 'romance', 'room', 'rose', 'round', 'rune', 'salmon', 'salt', 'sand', 'sandals', 'scandinavia', 'scientist', 'screen', 'screw', 'script', 'scuba', 'sea', 'seat', 'second', 'security', 'seoul', 'serpent', 'set', 'shaman', 'shepherd', 'shoe', 'shrimp', 'silk', 'singer', 'single', 'skull', 'sky', 'smile', 'snail', 'sniper', 'soldier', 'soprano', 'soup', 'spaniel', 'spice', 'spider', 'spiderman', 'spoon', 'spring', 'star', 'step', 'stomach', 'stone', 'store', 'storm', 'story', 'student', 'sugar', 'summit', 'surface', 'surgery', 'swan', 'swing', 'syria', 'system', 'tail', 'tea', 'team', 'technician', 'television', 'temperature', 'terrier', 'third', 'throw', 'ticket', 'tie', 'time', 'tissue', 'toe', 'toilet', 'tournament', 'tower', 'track', 'trained', 'trap', 'truck', 'tube', 'tune', 'turtle', 'twilight', 'underwear', 'unit', 'universe', 'update', 'usa', 'vampire', 'vehicle', 'venus', 'violin', 'voice', 'waiter', 'wales', 'war', 'website', 'wedding', 'week', 'well', 'western', 'wind', 'window', 'wing', 'winter', 'wizard', 'wolf', 'world', 'writer', 'yacht', 'year', 'zurich'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automaton\n"
     ]
    }
   ],
   "source": [
    "for w in new_words:\n",
    "    if w not in word:\n",
    "        print(w)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
